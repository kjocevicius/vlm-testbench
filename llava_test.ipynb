{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLaVA 1.6 Mistral Test (7B params)\n",
        "\n",
        "Highly capable VLM based on Mistral architecture with excellent performance.\n",
        "\n",
        "**Model:** `llava-hf/llava-v1.6-mistral-7b-hf`  \n",
        "**Size:** 7B parameters  \n",
        "**License:** Permissive  \n",
        "**Features:** Highly capable, excellent accuracy  \n",
        "**Requirements:** ~14GB disk, ~8GB RAM/VRAM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
        "from PIL import Image\n",
        "from vlm_utils import get_device_info, load_test_images, display_image, print_section, print_subsection\n",
        "\n",
        "device = get_device_info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Test Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_files = load_test_images()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load LLaVA 1.6 Mistral Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Loading LLaVA 1.6 Mistral...\")\n",
        "model_id = \"llava-hf/llava-v1.6-mistral-7b-hf\"\n",
        "\n",
        "# Determine dtype based on device\n",
        "use_float16 = torch.cuda.is_available() or torch.backends.mps.is_available()\n",
        "model_dtype = torch.float16 if use_float16 else torch.float32\n",
        "\n",
        "processor = LlavaNextProcessor.from_pretrained(model_id, use_fast=True)\n",
        "model = LlavaNextForConditionalGeneration.from_pretrained(\n",
        "    model_id,\n",
        "    dtype=model_dtype,\n",
        "    low_cpu_mem_usage=True\n",
        ").to(device)\n",
        "print(\"âœ“ LLaVA 1.6 Mistral loaded!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Inference Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def describe_image(image_path, prompt=\"Describe this image in detail.\"):\n",
        "    \"\"\"Generate description for an image using LLaVA 1.6 Mistral.\"\"\"\n",
        "    image = Image.open(image_path)\n",
        "    formatted_prompt = f\"[INST] <image>\\n{prompt} [/INST]\"\n",
        "    inputs = processor(formatted_prompt, image, return_tensors=\"pt\").to(device)\n",
        "    output = model.generate(**inputs, max_new_tokens=200)\n",
        "    description = processor.decode(output[0], skip_special_tokens=True)\n",
        "    return description\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test on All Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for image_path in image_files:\n",
        "    print_section(f\"Image: {image_path.name}\")\n",
        "    \n",
        "    display_image(image_path)\n",
        "    \n",
        "    print_subsection(\"ðŸ¦™ LLaVA 1.6 Mistral Description:\")\n",
        "    try:\n",
        "        desc = describe_image(image_path)\n",
        "        print(desc)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Prompts\n",
        "\n",
        "Try asking specific questions about an image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if image_files:\n",
        "    test_image = image_files[0]\n",
        "    \n",
        "    custom_prompts = [\n",
        "        \"What objects can you see in this image?\",\n",
        "        \"What colors are prominent in this image?\",\n",
        "        \"What is the main subject of this image?\"\n",
        "    ]\n",
        "    \n",
        "    print_section(f\"Custom Prompts - {test_image.name}\")\n",
        "    display_image(test_image)\n",
        "    \n",
        "    for prompt in custom_prompts:\n",
        "        print_subsection(f\"Q: {prompt}\")\n",
        "        answer = describe_image(test_image, prompt)\n",
        "        print(f\"A: {answer}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
